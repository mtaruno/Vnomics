{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sitting-buddy",
   "metadata": {},
   "source": [
    "# Implementing the Auto Encoder for DPF Prediction\n",
    "\n",
    "### Installation Notes:\n",
    "TensorFlow supports Python 3.8 as of May 2020, so we can regularly just use:\n",
    "    \n",
    "    pip install --upgrade tensorflow\n",
    "    \n",
    "to get it.\n",
    "\n",
    "My success message:\n",
    "    \n",
    "    Successfully installed absl-py-0.12.0 astunparse-1.6.3 cachetools-4.2.1 flatbuffers-1.12 gast-0.3.3 google-auth-1.28.0 google-auth-oauthlib-0.4.3 google-pasta-0.2.0 grpcio-1.32.0 h5py-2.10.0 keras-preprocessing-1.1.2 markdown-3.3.4 oauthlib-3.1.0 opt-einsum-3.3.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7.2 tensorboard-2.4.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.4.1 tensorflow-estimator-2.4.0 termcolor-1.1.0 wrapt-1.12.1\n",
    "\n",
    "### About Autoencoders\n",
    "\n",
    "Autoencoders are an unsupervised learning technique in which we leverage neural networks for the task of representation learning. Specifically, we'll design a neural network architecture such that we impose a bottleneck in the network which forces a compressed knowledge representation of the original input. If the input features were each independent of one another, this compression and subsequent reconstruction would be a very difficult task. However, if some sort of structure exists in the data (ie. correlations between input features), this structure can be learned and consequently leveraged when forcing the input through the network's bottleneck.\n",
    "\n",
    "Intro: https://www.jeremyjordan.me/autoencoders/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-lemon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "integrated-vulnerability",
   "metadata": {},
   "source": [
    "### Reproduction\n",
    "\n",
    "Try to recreate the results from the Medium article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-opportunity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-beach",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-program",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-livestock",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
